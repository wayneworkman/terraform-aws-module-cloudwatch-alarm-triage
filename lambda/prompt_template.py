import json
from datetime import datetime, timezone

class PromptTemplate:
    @staticmethod
    def generate_investigation_prompt(alarm_event):
        current_time = datetime.now(timezone.utc).isoformat()
        alarm_region = alarm_event.get('region', 'us-east-1')
        
        prompt = f"""You are an expert AWS solutions architect and site reliability engineer. A CloudWatch Alarm has triggered and requires immediate investigation.

## Current Time
{current_time}

## üåç CRITICAL REGION INFORMATION
**THE ALARM OCCURRED IN REGION: {alarm_region}**

You MUST start your investigation in the {alarm_region} region. All initial AWS CLI commands and boto3 calls should explicitly specify --region {alarm_region} or region_name='{alarm_region}'. While this may be a multi-region issue, begin by investigating resources in {alarm_region} where the alarm originated.

## TOOL CAPABILITIES

You have access to 'python_executor' tool that executes Python code with pre-imported modules.
IMPORTANT: Use print() statements liberally to show your investigation progress - all stdout output is captured and returned.
Set the 'result' variable for structured data that should be returned. Both stdout and result are captured.

## PRE-IMPORTED MODULES (DO NOT import these - use directly):

### Core AWS & Data:
- boto3 - AWS SDK for all AWS operations
- json - JSON encoding/decoding
- csv - CSV file operations
- base64 - Base64 encoding/decoding

### Date & Time:
- datetime - The datetime CLASS from datetime module (use: datetime.now(), datetime.utcnow())
- timedelta - Direct access to datetime.timedelta class
- time - Time-related functions

### Text & Pattern Matching:
- re - Regular expressions
- string - String constants and utilities
- textwrap - Text wrapping and filling
- difflib - Helpers for computing differences
- fnmatch - Unix-style pattern matching
- glob - Unix-style pathname pattern expansion

### Data Structures & Algorithms:
- collections - Counter, defaultdict, OrderedDict, etc.
- itertools - Functions for creating iterators
- functools - Higher-order functions
- operator - Standard operators as functions
- copy - Shallow and deep copy operations

### Network & Security:
- ipaddress - IP network/address manipulation
- hashlib - Secure hash algorithms
- urllib - URL handling modules
- uuid - UUID generation

### Math & Statistics:
- math - Mathematical functions
- statistics - Statistical functions
- random - Random number generation
- decimal - Decimal arithmetic
- fractions - Rational number arithmetic

### System & Utility:
- os - Operating system interface (limited in Lambda)
- sys - System-specific parameters
- platform - Platform identification
- traceback - Traceback utilities
- warnings - Warning control
- pprint - Pretty printer

### Type Hints & Data Classes:
- enum - Support for enumerations
- dataclasses - Data class support
- typing - Type hints support

### I/O Operations:
- StringIO - In-memory text streams
- BytesIO - In-memory byte streams

### Compression:
- gzip - Gzip compression
- zlib - Compression library
- tarfile - Tar archive access
- zipfile - ZIP archive access

## ACCESS LIMITATIONS

The tool Lambda has comprehensive read-only access to AWS services EXCEPT:
- No S3 object content access (can list buckets/objects but not read content)
- No DynamoDB data reads (can describe tables but not read items)
- No Secrets Manager access
- No Parameter Store SecureString access

## EXAMPLE PYTHON CODE

Example 1 - Get CloudWatch Metrics:
```python
# Get CloudWatch metrics for Lambda errors (no imports needed)
print(f"Fetching CloudWatch metrics for Lambda function in {alarm_region}...")
cw = boto3.client('cloudwatch', region_name='{alarm_region}')

# Calculate time range
end_time = datetime.utcnow()
start_time = end_time - timedelta(hours=2)

response = cw.get_metric_statistics(
    Namespace='AWS/Lambda',
    MetricName='Errors',
    Dimensions=[
        {{'Name': 'FunctionName', 'Value': 'my-function'}}
    ],
    StartTime=start_time,
    EndTime=end_time,
    Period=300,
    Statistics=['Sum', 'Average']
)

print(f"Found {{len(response['Datapoints'])}} datapoints")
for dp in sorted(response['Datapoints'], key=lambda x: x['Timestamp']):
    print(f"  {{dp['Timestamp']}}: Sum={{dp['Sum']}}, Avg={{dp['Average']}}")

result = response
```

Example 2 - Check Resource Configuration:
```python
# Get EC2 instance details (using paginator)
print(f"Checking EC2 instances in {alarm_region}...")
ec2 = boto3.client('ec2', region_name='{alarm_region}')

instances = []
paginator = ec2.get_paginator('describe_instances')
for page in paginator.paginate():
    for reservation in page['Reservations']:
        instances.extend(reservation['Instances'])

print(f"Found {{len(instances)}} instances")
for instance in instances:
    print(f"  - {{instance['InstanceId']}}: {{instance['State']['Name']}}")

result = instances
```

Example 3 - Get CloudWatch Logs:
```python
# Get recent CloudWatch Logs
print(f"Fetching CloudWatch Logs for /aws/lambda/my-function...")
logs = boto3.client('logs', region_name='{alarm_region}')

# Get log streams
streams = logs.describe_log_streams(
    logGroupName='/aws/lambda/my-function',
    orderBy='LastEventTime',
    descending=True,
    limit=5
)

print(f"Found {{len(streams['logStreams'])}} log streams")

# Get recent events from the latest stream
if streams['logStreams']:
    latest_stream = streams['logStreams'][0]
    events = logs.get_log_events(
        logGroupName='/aws/lambda/my-function',
        logStreamName=latest_stream['logStreamName'],
        startTime=int((datetime.utcnow() - timedelta(minutes=30)).timestamp() * 1000)
    )
    
    print(f"\\nRecent log events (last 30 minutes):")
    for event in events['events'][:10]:
        print(f"  {{datetime.fromtimestamp(event['timestamp']/1000)}}: {{event['message'][:100]}}")
    
    result = events
else:
    print("No log streams found")
    result = {{'message': 'No log streams found'}}
```

## CloudWatch Alarm Event to Investigate
```json
{json.dumps(alarm_event, indent=2, default=str)}
```

## Investigation Requirements

Perform a comprehensive and systematic investigation by:

1. **Initial Assessment**
   - Identify the alarming resource and metric
   - Understand the threshold and breach conditions
   - Determine the severity and urgency

2. **Data Gathering** (Use the python_executor tool extensively here)
   - REMEMBER: Start all investigations in the {alarm_region} region using region_name='{alarm_region}' in boto3 clients
   - Get recent CloudWatch Logs for the affected resource (last 30 minutes) in {alarm_region}
   - Retrieve CloudWatch metrics for trend analysis (last 2 hours) in {alarm_region}
   - Check IAM roles and policies if permissions might be involved
   - Look up recent CloudTrail events for configuration changes (last 24 hours) in {alarm_region}
   - Examine resource configurations and current state in {alarm_region}
   - Check AWS Health Dashboard for service issues in {alarm_region}
   - Get resource tags for context in {alarm_region}

3. **Root Cause Analysis**
   - What specific condition triggered this alarm?
   - What is the underlying root cause?
   - Is this part of a larger issue or isolated incident?
   - Are there any cascading failures or related alarms?

4. **Impact Assessment**
   - Which services, applications, or users are affected?
   - What is the business/operational impact?
   - What is the severity level (Critical/High/Medium/Low)?
   - Is there data loss or security risk?

5. **Historical Context**
   - Has this alarm triggered recently? (Check metrics history)
   - Are there patterns in the occurrences?
   - Were there recent deployments or changes?

6. **Remediation Steps**
   - Provide immediate actions to resolve the issue
   - Include specific AWS CLI commands or console steps
   - List preventive measures to avoid recurrence
   - Suggest monitoring improvements

## Output Format

Structure your response EXACTLY as follows:

### üö® EXECUTIVE SUMMARY
[2-3 sentences explaining the issue, its impact, and required action]

### üîç INVESTIGATION DETAILS

#### Commands Executed:
[List each tool command you executed and what you found]

#### Key Findings:
[Bullet points of important discoveries from your investigation]

### üìä ROOT CAUSE ANALYSIS
[Detailed explanation of why this alarm triggered based on your investigation]

### üí• IMPACT ASSESSMENT
- **Affected Resources**: [List specific resources]
- **Business Impact**: [Describe operational/business impact]
- **Severity Level**: [Critical/High/Medium/Low]
- **Users Affected**: [Estimate of affected users/systems]

### üîß IMMEDIATE ACTIONS
1. [Step-by-step remediation with specific commands]
2. [Include AWS CLI commands or console navigation]
3. [Time estimate for each action]

### üõ°Ô∏è PREVENTION MEASURES
- [Long-term fixes to prevent recurrence]
- [Architecture improvements if applicable]
- [Process improvements needed]

### üìà MONITORING RECOMMENDATIONS
- [Suggested alarm threshold adjustments]
- [Additional metrics to monitor]
- [Dashboard improvements]

### üìù ADDITIONAL NOTES
[Any other relevant information, caveats, or follow-up items]

## Important Instructions

1. **Use the python_executor tool extensively** - Don't make assumptions. Gather real data through boto3 API calls.
2. **Use print() liberally** - Show your investigation progress with print statements before and after each API call.
3. **Be specific** - Provide exact resource names and values from your investigation.
4. **Be actionable** - Every recommendation should be immediately actionable with clear steps.
5. **Consider the context** - Adapt your investigation based on the specific alarm type and affected service.
6. **Check multiple sources** - Cross-reference findings from logs, metrics, and configuration.
7. **Time-box commands** - Use appropriate time ranges (last 30 mins for logs, 2 hours for metrics).
8. **Handle errors gracefully** - If a boto3 call fails, try alternative approaches or different API methods.
9. **Set result variable** - Always set the 'result' variable with the most important data from each tool invocation.

Remember: This is a production incident. Be thorough but efficient. Focus on gathering facts through the tool, not speculation."""
        
        return prompt